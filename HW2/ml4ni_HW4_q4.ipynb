{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ad2c12",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd16aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0810a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b335a3",
   "metadata": {},
   "source": [
    "### Data input and train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_4 = '/Users/charliejiang/Documents/Stanford/Machine-Learning-for-Neuroimaging/HW2/data_assignment_2/lgg-mri-segmentation/kaggle_3m'\n",
    "\n",
    "metadata = pd.read_csv(data_path_4 + '/data.csv')\n",
    "patient_id = metadata['Patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b86b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "folder_lst = []\n",
    "for i in os.listdir(data_path_4):\n",
    "    if i[0:12] in patient_id.values:\n",
    "        folder_lst.append(os.path.join(data_path_4,i))\n",
    "print(len(folder_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1cd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lst = []\n",
    "mask_lst = []\n",
    "#Obtain paths for both mask and MRI images at same time, ensuring path order is preservered\n",
    "for i in folder_lst:\n",
    "    file_lst = os.listdir(i)\n",
    "    for j in file_lst:\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            img_lst.append(os.path.join(data_path_4,i,j))\n",
    "            mask_lst.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0f7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78759b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/charliejiang/Documents/Stanford/Machine-Learning-for-Neuroimaging/HW2/data_assignment_2/lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_9_mask.tif'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9009239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        ...,\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0]],\n",
       "\n",
       "       [[1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        ...,\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0]],\n",
       "\n",
       "       [[1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]],\n",
       "\n",
       "       [[1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]],\n",
       "\n",
       "       [[1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread(img_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a440dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if input data is standarized\n",
    "shape_0 =  cv2.imread(img_lst[0]).shape\n",
    "for i in img_lst:    \n",
    "    if cv2.imread(i).shape != shape_0:\n",
    "        print(\"This aint it\")\n",
    "        break\n",
    "mshape_0 =  cv2.imread(img_lst[0]).shape    \n",
    "if mshape_0 != shape_0:\n",
    "    print(\"Nah\")\n",
    "for i in mask_lst:    \n",
    "    if cv2.imread(i).shape != mshape_0:\n",
    "        print(\"This aint it\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb75c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_shape = (shape_0[0],shape_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ace0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_imgs,test_imgs,train_val_masks,test_masks = train_test_split(img_lst,mask_lst,test_size=0.2, random_state=42)\n",
    "train_imgs,val_imgs,train_masks,val_masks = train_test_split(train_val_imgs,train_val_masks,test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb5c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n",
      "393\n",
      "786\n"
     ]
    }
   ],
   "source": [
    "#Verify split is correct\n",
    "\n",
    "print(len(train_imgs))\n",
    "print(len(val_imgs))\n",
    "print(len(test_imgs))\n",
    "\n",
    "for i in val_imgs:\n",
    "    if i in train_imgs or i in test_imgs:\n",
    "        print('Error')\n",
    "        break\n",
    "for j in val_masks:\n",
    "    if j in train_masks or j in test_masks:\n",
    "        print('Error')\n",
    "        break\n",
    "        \n",
    "for i in test_imgs:\n",
    "    if i in train_imgs:\n",
    "        print('Error')\n",
    "        break\n",
    "for j in test_masks:\n",
    "    if j in train_masks:\n",
    "        print('Error')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, imagePaths, maskPaths):\n",
    "        self.imagePaths = imagePaths\n",
    "        self.maskPaths = maskPaths\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "    def __getitem__(self, idx):\n",
    "        imagePath = self.imagePaths[idx]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.maskPaths[idx], 0)\n",
    "        \n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6dad432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 2750 examples in the training set...\n",
      "[INFO] found 393 examples in the val set...\n",
      "[INFO] found 786 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "trainDS = SegmentationDataset(imagePaths=train_imgs, maskPaths=train_masks)\n",
    "valDS = SegmentationDataset(imagePaths=val_imgs, maskPaths=val_masks)\n",
    "testDS = SegmentationDataset(imagePaths=test_imgs, maskPaths=test_masks)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(valDS)} examples in the val set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,batch_size = BATCH_SIZE, pin_memory=True)\n",
    "\n",
    "valLoader = DataLoader(valDS, shuffle=False,batch_size = BATCH_SIZE,pin_memory=True)\n",
    "\n",
    "testLoader = DataLoader(testDS, shuffle=False,batch_size = BATCH_SIZE, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8446cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec429e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Module):\n",
    "    def __init__(self, channels=(3, 16, 32, 64)):\n",
    "        super().__init__()\n",
    "        self.encBlocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.pool = MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        blockOutputs = []\n",
    "        for block in self.encBlocks:\n",
    "            x = block(x)\n",
    "            blockOutputs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return blockOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd4405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Module):\n",
    "    def __init__(self, channels=(64, 32, 16)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = ModuleList(\n",
    "            [ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.dec_blocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                for i in range(len(channels) - 1)])\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            x = self.upconvs[i](x)\n",
    "            encFeat = self.crop(encFeatures[i], x)\n",
    "            x = torch.cat([x, encFeat], dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    def crop(self, encFeatures, x):\n",
    "        (_, _, H, W) = x.shape\n",
    "        encFeatures = CenterCrop([H, W])(encFeatures)\n",
    "        return encFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc57ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Module):\n",
    "    def __init__(self, encChannels=(3, 16, 32, 64),\n",
    "                 decChannels=(64, 32, 16),\n",
    "                 nbClasses=1, retainDim=True,\n",
    "                 outSize=initial_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(encChannels)\n",
    "        self.decoder = Decoder(decChannels)\n",
    "\n",
    "        self.head = Conv2d(decChannels[-1], nbClasses, 1)\n",
    "        self.retainDim = retainDim\n",
    "        self.outSize = outSize\n",
    "    def forward(self, x):\n",
    "        encFeatures = self.encoder(x)\n",
    "        decFeatures = self.decoder(encFeatures[::-1][0],encFeatures[::-1][1:])\n",
    "        map = self.head(decFeatures)\n",
    "        if self.retainDim:\n",
    "            map = F.interpolate(map, self.outSize)\n",
    "        return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a7cdc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder): Encoder(\n",
      "    (encBlocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (upconvs): ModuleList(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (dec_blocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "u_net=UNet()\n",
    "print(u_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0150094",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lossfun = BCEWithLogitsLoss()\n",
    "optimizer = Adam(u_net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41bc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coeff(y_pred, y_true):\n",
    "        inter = np.dot(y_pred, y_true)\n",
    "        union = np.sum(y_pred) + np.sum(y_true) - inter\n",
    "        jaccard_index = inter/union\n",
    "\n",
    "        return jaccard_index.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df7ae86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_binary(y_pred, y_true):\n",
    "        eps = 0.0001\n",
    "        inter = np.dot(y_pred, y_true)\n",
    "        union = np.sum(y_pred) + np.sum(y_true) - inter\n",
    "        return ((2 * inter.float() + eps) / (union.float() + eps)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a24562fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "def train_unet(unet,trainLoader,valLoader, opt,lossFunc,epoch_cnt = 100):\n",
    "    # Training model\n",
    "    startTime = time.time()\n",
    "    \n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "    train_dice = []\n",
    "    valid_dice = []\n",
    "    \n",
    "    for e in range(epoch_cnt):\n",
    "        unet.train()\n",
    "        \n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "        pred_val_lst = []\n",
    "        train_epoch_loss = []\n",
    "\n",
    "        for (i, (x, y)) in enumerate(trainLoader):\n",
    "            pred = unet(x)\n",
    "            loss = lossFunc(pred, y)\n",
    "            \n",
    "            train_epoch_loss.append(loss)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            \n",
    "            pred_lst.append(pred.detach().numpy())\n",
    "            target_lst.append(y.detach().numpy())\n",
    "        \n",
    "        pred_lst = np.concatenate(pred_lst, axis=0)\n",
    "        target_lst =  np.concatenate(target_lst, axis=0)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            unet.eval()\n",
    "            for (x, y) in valLoader:\n",
    "                pred = unet(x)\n",
    "                pred_val_lst.append(pred.detach().numpy())\n",
    "                val_epoch_loss.append(loss(pred,y))\n",
    "            \n",
    "        pred_val_lst = np.concatenate(pred_lst, axis=0)\n",
    "                                    \n",
    "        avgTrainLoss = train_epoch_loss.mean()\n",
    "        avgTrainAccuracy = metrics.accuracy_score(target_lst, pred_lst.argmax(1))\n",
    "        \n",
    "        avgValLoss = val_epoch_loss.mean()\n",
    "    \n",
    "        train_accuracy.append(avgTrainAccuracy)\n",
    "        val_accuracy.append(avgValAccuracy)\n",
    "        train_loss.append(avgTrainLoss)\n",
    "        val_loss.append(avgValLoss)\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {e}: Training Accuracy: {avgTrainAccuracy} Loss: {avgTrainLoss}\")\n",
    "        print(f\"Epoch {e}: Validation Accuracy: {avgTrainAccuracy} Loss: {avgTrainLoss}\")\n",
    "\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "        endTime - startTime))\n",
    "    \n",
    "    #Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(u_net,trainLoader,valLoader,optimizer,lossfun,epoch_cnt = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb629e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241d091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
