{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ad2c12",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd16aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b5c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef1893",
   "metadata": {},
   "source": [
    "### Data input and train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_4 = '/Users/charliejiang/Documents/Stanford/Machine-Learning-for-Neuroimaging/HW2/data_assignment_2/lgg-mri-segmentation/kaggle_3m'\n",
    "\n",
    "metadata = pd.read_csv(data_path_4 + '/data.csv')\n",
    "patient_id = metadata['Patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b86b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "folder_lst = []\n",
    "for i in os.listdir(data_path_4):\n",
    "    if i[0:12] in patient_id.values:\n",
    "        folder_lst.append(os.path.join(data_path_4,i))\n",
    "print(len(folder_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c081a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders, test_folders = train_test_split(folder_lst,test_size=0.2, random_state=42)\n",
    "train_folders,val_folders = train_test_split(train_folders,test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8f36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 11 22\n"
     ]
    }
   ],
   "source": [
    "print(len(train_folders),len(val_folders),len(test_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b7735b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "val_imgs = []\n",
    "test_imgs = []\n",
    "train_masks = []\n",
    "val_masks = []\n",
    "test_masks = []\n",
    "\n",
    "\n",
    "for i in train_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            train_imgs.append(os.path.join(data_path_4,i,j))\n",
    "            train_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')\n",
    "            \n",
    "for i in val_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            val_imgs.append(os.path.join(data_path_4,i,j))\n",
    "            val_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')\n",
    "            \n",
    "            \n",
    "for i in test_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            test_imgs.append(os.path.join(data_path_4,i,j))\n",
    "            test_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, imagePaths, maskPaths,transforms):\n",
    "        self.imagePaths = imagePaths\n",
    "        self.maskPaths = maskPaths\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "    def __getitem__(self, idx):\n",
    "        imagePath = self.imagePaths[idx]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.maskPaths[idx], 0)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask)\n",
    "        \n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e2b10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 2833 examples in the training set...\n",
      "[INFO] found 378 examples in the val set...\n",
      "[INFO] found 718 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainDS = SegmentationDataset(imagePaths=train_imgs, maskPaths=train_masks,transforms = transform)\n",
    "valDS = SegmentationDataset(imagePaths=val_imgs, maskPaths=val_masks, transforms = transform)\n",
    "testDS = SegmentationDataset(imagePaths=test_imgs, maskPaths=test_masks, transforms = transform)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(valDS)} examples in the val set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,batch_size = BATCH_SIZE, pin_memory=True)\n",
    "\n",
    "valLoader = DataLoader(valDS, shuffle=False,batch_size = BATCH_SIZE,pin_memory=True)\n",
    "\n",
    "testLoader = DataLoader(testDS, shuffle=False,batch_size = BATCH_SIZE, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ef32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e33a69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_shape = (next(iter(trainDS))[1].shape[1],next(iter(trainDS))[1].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "294c576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25954a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Module):\n",
    "    def __init__(self, channels=(3, 16, 32, 64)):\n",
    "        super().__init__()\n",
    "        self.encBlocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.pool = MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        blockOutputs = []\n",
    "        for block in self.encBlocks:\n",
    "            x = block(x)\n",
    "            blockOutputs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return blockOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48c8e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Module):\n",
    "    def __init__(self, channels=(64, 32, 16)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = ModuleList(\n",
    "            [ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.dec_blocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                for i in range(len(channels) - 1)])\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            x = self.upconvs[i](x)\n",
    "            encFeat = self.crop(encFeatures[i], x)\n",
    "            x = torch.cat([x, encFeat], dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    def crop(self, encFeatures, x):\n",
    "        (_, _, H, W) = x.shape\n",
    "        encFeatures = CenterCrop([H, W])(encFeatures)\n",
    "        return encFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49e42169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Module):\n",
    "    def __init__(self, encChannels=(3, 16, 32, 64),\n",
    "                 decChannels=(64, 32, 16),\n",
    "                 nbClasses=1, retainDim=True,\n",
    "                 outSize=initial_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(encChannels)\n",
    "        self.decoder = Decoder(decChannels)\n",
    "\n",
    "        self.head = Conv2d(decChannels[-1], nbClasses, 1)\n",
    "        self.retainDim = retainDim\n",
    "        self.outSize = outSize\n",
    "    def forward(self, x):\n",
    "        encFeatures = self.encoder(x)\n",
    "        decFeatures = self.decoder(encFeatures[::-1][0],encFeatures[::-1][1:])\n",
    "        map = self.head(decFeatures)\n",
    "        if self.retainDim:\n",
    "            map = F.interpolate(map, self.outSize)\n",
    "        return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4d9f0e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder): Encoder(\n",
      "    (encBlocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (upconvs): ModuleList(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (dec_blocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "u_net=UNet()\n",
    "print(u_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "976dde4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lossfun = BCEWithLogitsLoss()\n",
    "optimizer = Adam(u_net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8254f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "#from sklearn.metrics import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11a013f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "valSteps  = len(valDS) // BATCH_SIZE\n",
    "testSteps = len(testDS) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7af9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "def train_unet(unet,trainLoader,valLoader, opt,lossFunc,epoch_cnt = 100):\n",
    "    # Training model\n",
    "    startTime = time.time()\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    traindice_lst = []\n",
    "    #JI_lst = []\n",
    "    \n",
    "    for e in tqdm(range(epoch_cnt)):\n",
    "        unet.train()\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        train_JI = 0\n",
    "        val_JI = 0\n",
    "        \n",
    "        for (i, (x, y)) in enumerate(trainLoader):\n",
    "            pred = unet(x)\n",
    "            loss = lossFunc(pred, y)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            #JI = jaccard_score(pred.detach().numpy(),y)\n",
    "            total_train_loss += loss\n",
    "            #train_JI+= JI\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            unet.eval()\n",
    "            for (x, y) in valLoader:\n",
    "                pred = unet(x)\n",
    "                total_val_loss += lossFunc(pred,y)\n",
    "                #val_JI += jaccard_score(pred.detach().numpy(),y)\n",
    "            \n",
    "\n",
    "        avgTrainLoss = total_train_loss/trainSteps\n",
    "        avgValLoss = total_val_loss/valSteps\n",
    "        \n",
    "        #avgTrainJI = train_JI/trainSteps\n",
    "        #avgValJI = val_JI/valSteps\n",
    "        \n",
    "        print(f\"Epoch {e}: Training Loss: {avgTrainLoss} mIOU: \")\n",
    "        print(f\"           Validation Loss: {avgValLoss} mIOU: \")\n",
    "\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "        endTime - startTime))\n",
    "    \n",
    "    #Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d132e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 1/100 [06:08<10:08:17, 368.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 0.10560795664787292 mIOU: \n",
      "           Validation Loss: 0.030888782814145088 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                       | 2/100 [11:50<9:36:01, 352.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.03485293686389923 mIOU: \n",
      "           Validation Loss: 0.027261190116405487 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                      | 3/100 [18:08<9:49:25, 364.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss: 0.03301425278186798 mIOU: \n",
      "           Validation Loss: 0.02686992473900318 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                      | 4/100 [24:16<9:45:10, 365.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss: 0.03152129054069519 mIOU: \n",
      "           Validation Loss: 0.030174775049090385 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                      | 5/100 [30:29<9:43:16, 368.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss: 0.02983386442065239 mIOU: \n",
      "           Validation Loss: 0.02277674525976181 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                     | 6/100 [36:44<9:40:53, 370.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss: 0.02806568704545498 mIOU: \n",
      "           Validation Loss: 0.02509339340031147 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                     | 7/100 [42:51<9:32:47, 369.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss: 0.02616105228662491 mIOU: \n",
      "           Validation Loss: 0.020944060757756233 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▉                                  | 8/100 [1:14:21<21:48:28, 853.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss: 0.02616053819656372 mIOU: \n",
      "           Validation Loss: 0.0206635482609272 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▎                                 | 9/100 [1:19:53<17:27:21, 690.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss: 0.024519948288798332 mIOU: \n",
      "           Validation Loss: 0.02189638838171959 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▌                                | 10/100 [1:26:09<14:50:10, 593.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss: 0.024398623034358025 mIOU: \n",
      "           Validation Loss: 0.018476592376828194 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███▉                                | 11/100 [1:32:24<13:00:58, 526.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss: 0.02347376197576523 mIOU: \n",
      "           Validation Loss: 0.01847982592880726 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▎                               | 12/100 [1:38:23<11:37:16, 475.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss: 0.023629145696759224 mIOU: \n",
      "           Validation Loss: 0.019028041511774063 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▋                               | 13/100 [1:52:31<14:13:08, 588.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss: 0.022552764043211937 mIOU: \n",
      "           Validation Loss: 0.018341796472668648 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████                               | 14/100 [1:59:05<12:39:21, 529.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss: 0.023123174905776978 mIOU: \n",
      "           Validation Loss: 0.01834752783179283 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▍                              | 15/100 [2:05:17<11:23:00, 482.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training Loss: 0.022049862891435623 mIOU: \n",
      "           Validation Loss: 0.019373415037989616 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▊                              | 16/100 [2:12:55<11:04:37, 474.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss: 0.0221430491656065 mIOU: \n",
      "           Validation Loss: 0.017744479700922966 mIOU: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████                              | 17/100 [2:20:02<10:37:01, 460.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss: 0.02178223989903927 mIOU: \n",
      "           Validation Loss: 0.018432416021823883 mIOU: \n"
     ]
    }
   ],
   "source": [
    "train_unet(u_net,trainLoader,valLoader,optimizer,lossfun,epoch_cnt = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c2bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f279c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
