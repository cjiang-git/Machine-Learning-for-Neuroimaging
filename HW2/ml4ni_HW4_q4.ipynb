{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ad2c12",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd16aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c7cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359984e",
   "metadata": {},
   "source": [
    "### Data input and train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_4 = '/Users/charliejiang/Documents/Stanford/Machine-Learning-for-Neuroimaging/HW2/data_assignment_2/lgg-mri-segmentation/kaggle_3m'\n",
    "\n",
    "metadata = pd.read_csv(data_path_4 + '/data.csv')\n",
    "patient_id = metadata['Patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b86b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "folder_lst = []\n",
    "for i in os.listdir(data_path_4):\n",
    "    if i[0:12] in patient_id.values:\n",
    "        folder_lst.append(os.path.join(data_path_4,i))\n",
    "print(len(folder_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d091d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders, test_folders = train_test_split(folder_lst,test_size=0.2, random_state=42)\n",
    "train_folders,val_folders = train_test_split(train_folders,test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96ea22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 11 22\n"
     ]
    }
   ],
   "source": [
    "print(len(train_folders),len(val_folders),len(test_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d479ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "val_imgs = []\n",
    "test_imgs = []\n",
    "train_masks = []\n",
    "val_masks = []\n",
    "test_masks = []\n",
    "\n",
    "\n",
    "for i in train_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            train_imgs.append(os.path.join(data_path_4,i,j))\n",
    "            train_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')\n",
    "            \n",
    "for i in val_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            val_imgs.append(os.path.join(data_path_4,i,j))\n",
    "        else:\n",
    "            val_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')\n",
    "            \n",
    "            \n",
    "for i in test_folders:\n",
    "    for j in os.listdir(i):\n",
    "        if j[-8:] != 'mask.tif':\n",
    "            test_imgs.append(os.path.join(data_path_4,i,j))\n",
    "        else:\n",
    "            test_masks.append(os.path.join(data_path_4,i,j[:-4])+'_mask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, imagePaths, maskPaths,transforms):\n",
    "        self.imagePaths = imagePaths\n",
    "        self.maskPaths = maskPaths\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "    def __getitem__(self, idx):\n",
    "        imagePath = self.imagePaths[idx]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.maskPaths[idx], 0)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask)\n",
    "        \n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71083b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 2833 examples in the training set...\n",
      "[INFO] found 378 examples in the val set...\n",
      "[INFO] found 718 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainDS = SegmentationDataset(imagePaths=train_imgs, maskPaths=train_masks,transforms = transform)\n",
    "valDS = SegmentationDataset(imagePaths=val_imgs, maskPaths=val_masks, transforms = transform)\n",
    "testDS = SegmentationDataset(imagePaths=test_imgs, maskPaths=test_masks, transforms = transform)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(valDS)} examples in the val set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,batch_size = BATCH_SIZE, pin_memory=True)\n",
    "\n",
    "valLoader = DataLoader(valDS, shuffle=False,batch_size = BATCH_SIZE,pin_memory=True)\n",
    "\n",
    "testLoader = DataLoader(testDS, shuffle=False,batch_size = BATCH_SIZE, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c59f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_shape = (next(iter(trainDS))[1].shape[1],next(iter(trainDS))[1].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51922374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "886092de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Module):\n",
    "    def __init__(self, channels=(3, 16, 32, 64)):\n",
    "        super().__init__()\n",
    "        self.encBlocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.pool = MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        blockOutputs = []\n",
    "        for block in self.encBlocks:\n",
    "            x = block(x)\n",
    "            blockOutputs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return blockOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530539ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Module):\n",
    "    def __init__(self, channels=(64, 32, 16)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = ModuleList(\n",
    "            [ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
    "                 for i in range(len(channels) - 1)])\n",
    "        self.dec_blocks = ModuleList(\n",
    "            [DConvBlock(channels[i], channels[i + 1])\n",
    "                for i in range(len(channels) - 1)])\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            x = self.upconvs[i](x)\n",
    "            encFeat = self.crop(encFeatures[i], x)\n",
    "            x = torch.cat([x, encFeat], dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    def crop(self, encFeatures, x):\n",
    "        (_, _, H, W) = x.shape\n",
    "        encFeatures = CenterCrop([H, W])(encFeatures)\n",
    "        return encFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6edb24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Module):\n",
    "    def __init__(self, encChannels=(3, 16, 32, 64),\n",
    "                 decChannels=(64, 32, 16),\n",
    "                 nbClasses=1, retainDim=True,\n",
    "                 outSize=initial_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(encChannels)\n",
    "        self.decoder = Decoder(decChannels)\n",
    "\n",
    "        self.head = Conv2d(decChannels[-1], nbClasses, 1)\n",
    "        self.retainDim = retainDim\n",
    "        self.outSize = outSize\n",
    "    def forward(self, x):\n",
    "        encFeatures = self.encoder(x)\n",
    "        decFeatures = self.decoder(encFeatures[::-1][0],encFeatures[::-1][1:])\n",
    "        map = self.head(decFeatures)\n",
    "        if self.retainDim:\n",
    "            map = F.interpolate(map, self.outSize)\n",
    "        return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c1eb3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder): Encoder(\n",
      "    (encBlocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (upconvs): ModuleList(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (dec_blocks): ModuleList(\n",
      "      (0): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): DConvBlock(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "u_net=UNet()\n",
    "print(u_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2004d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lossfun = BCEWithLogitsLoss()\n",
    "optimizer = Adam(u_net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95d5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "#from sklearn.metrics import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35bcc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "valSteps  = len(valDS) // BATCH_SIZE\n",
    "testSteps = len(testDS) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59015b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "def train_unet(unet,trainLoader,valLoader, opt,lossFunc,epoch_cnt = 100):\n",
    "    # Training model\n",
    "    startTime = time.time()\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    traindice_lst = []\n",
    "    #JI_lst = []\n",
    "    \n",
    "    for e in tqdm(range(epoch_cnt)):\n",
    "        unet.train()\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        train_JI = 0\n",
    "        val_JI = 0\n",
    "        \n",
    "        for (i, (x, y)) in enumerate(trainLoader):\n",
    "            pred = unet(x)\n",
    "            loss = lossFunc(pred, y)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            #JI = jaccard_score(pred.detach().numpy(),y)\n",
    "            total_train_loss += loss\n",
    "            #train_JI+= JI\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            unet.eval()\n",
    "            for (x, y) in valLoader:\n",
    "                pred = unet(x)\n",
    "                total_val_loss += lossFunc(pred,y)\n",
    "                #val_JI += jaccard_score(pred.detach().numpy(),y)\n",
    "            \n",
    "\n",
    "        avgTrainLoss = total_train_loss/trainSteps\n",
    "        avgValLoss = total_val_loss/valSteps\n",
    "        \n",
    "        #avgTrainJI = train_JI/trainSteps\n",
    "        #avgValJI = val_JI/valSteps\n",
    "        \n",
    "        print(f\"Epoch {e}: Training Loss: {avgTrainLoss} mIOU: \")\n",
    "        print(f\"           Validation Loss: {avgValLoss} mIOU: \")\n",
    "\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "        endTime - startTime))\n",
    "    \n",
    "    #Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bcce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_unet(u_net,trainLoader,valLoader,optimizer,lossfun,epoch_cnt = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a862ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ff4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
